{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thanawit/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/thanawit/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout, Activation, Flatten, Conv2D, MaxPooling2D,BatchNormalization\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "import os \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialte the variable\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 200\n",
    "data_augmentation  = True\n",
    "num_predictions = 20 \n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#downloading the dataset\n",
    "\n",
    "(x_train , y_train) , (x_test , y_test ) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert class to binary class\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test =  keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Layer\n",
    "\n",
    "model = Sequential()\n",
    "#Conv2D Filter = filter size, kernel size, stride , padding , format , dilation rate , activation , biased, initializer, bias initilizaer, more \n",
    "\n",
    "#Block 1 \n",
    "model.add(Conv2D( 32 , (3,3) , padding='same',input_shape = x_train.shape[1:]  ))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32 , (3,3)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "#Block 2 \n",
    "model.add(Conv2D(64, (3,3) , padding='same'))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64 , (3,3)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "#Connecting it to Classification\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 150:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n"
     ]
    }
   ],
   "source": [
    "#initiate training lost \n",
    "opt = keras.optimizers.rmsprop(lr_schedule(0), decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "#meaning all the result\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subtract mean to make it more normalize\n",
    "x_train_mean = np.mean(x_train, axis=0)\n",
    "x_train -= x_train_mean\n",
    "x_test -= x_train_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Learning rate:  0.001\n",
      "Epoch 1/200\n",
      "50000/50000 [==============================] - 12s - loss: 1.4966 - acc: 0.5115 - val_loss: 1.1059 - val_acc: 0.6324\n",
      "Learning rate:  0.001\n",
      "Epoch 2/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.9672 - acc: 0.6674 - val_loss: 0.8971 - val_acc: 0.6998\n",
      "Learning rate:  0.001\n",
      "Epoch 3/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.8222 - acc: 0.7192 - val_loss: 0.9274 - val_acc: 0.7150\n",
      "Learning rate:  0.001\n",
      "Epoch 4/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.7323 - acc: 0.7527 - val_loss: 0.7540 - val_acc: 0.7500\n",
      "Learning rate:  0.001\n",
      "Epoch 5/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.6573 - acc: 0.7745 - val_loss: 0.7563 - val_acc: 0.7597\n",
      "Learning rate:  0.001\n",
      "Epoch 6/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.5899 - acc: 0.7986 - val_loss: 0.6791 - val_acc: 0.7826\n",
      "Learning rate:  0.001\n",
      "Epoch 7/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.5269 - acc: 0.8185 - val_loss: 0.6677 - val_acc: 0.7834\n",
      "Learning rate:  0.001\n",
      "Epoch 8/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.4769 - acc: 0.8340 - val_loss: 0.6778 - val_acc: 0.7842\n",
      "Learning rate:  0.001\n",
      "Epoch 9/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.4254 - acc: 0.8542 - val_loss: 0.6748 - val_acc: 0.7961\n",
      "Learning rate:  0.001\n",
      "Epoch 10/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.3874 - acc: 0.8659 - val_loss: 0.6944 - val_acc: 0.7961\n",
      "Learning rate:  0.001\n",
      "Epoch 11/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.3495 - acc: 0.8791 - val_loss: 0.6562 - val_acc: 0.8008\n",
      "Learning rate:  0.001\n",
      "Epoch 12/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.3153 - acc: 0.8913 - val_loss: 0.7172 - val_acc: 0.7885\n",
      "Learning rate:  0.001\n",
      "Epoch 13/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.2887 - acc: 0.9005 - val_loss: 0.7081 - val_acc: 0.8002\n",
      "Learning rate:  0.001\n",
      "Epoch 14/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.2619 - acc: 0.9087 - val_loss: 0.6921 - val_acc: 0.8123\n",
      "Learning rate:  0.001\n",
      "Epoch 15/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.2425 - acc: 0.9164 - val_loss: 0.7136 - val_acc: 0.7983\n",
      "Learning rate:  0.001\n",
      "Epoch 16/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.2232 - acc: 0.9228 - val_loss: 0.7202 - val_acc: 0.8066\n",
      "Learning rate:  0.001\n",
      "Epoch 17/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.2096 - acc: 0.9274 - val_loss: 0.7737 - val_acc: 0.8119\n",
      "Learning rate:  0.001\n",
      "Epoch 18/200\n",
      "50000/50000 [==============================] - 11s - loss: 0.1949 - acc: 0.9326 - val_loss: 0.7625 - val_acc: 0.8145\n",
      "Learning rate:  0.001\n",
      "Epoch 19/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.1869 - acc: 0.9351 - val_loss: 0.7694 - val_acc: 0.8077\n",
      "Learning rate:  0.001\n",
      "Epoch 20/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.1758 - acc: 0.9394 - val_loss: 0.8081 - val_acc: 0.8105\n",
      "Learning rate:  0.001\n",
      "Epoch 21/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.1637 - acc: 0.9436 - val_loss: 0.8648 - val_acc: 0.8101\n",
      "Learning rate:  0.001\n",
      "Epoch 22/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.1597 - acc: 0.9451 - val_loss: 0.8702 - val_acc: 0.8085\n",
      "Learning rate:  0.001\n",
      "Epoch 23/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.1531 - acc: 0.9488 - val_loss: 0.8831 - val_acc: 0.8108\n",
      "Learning rate:  0.001\n",
      "Epoch 24/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.1456 - acc: 0.9516 - val_loss: 0.9381 - val_acc: 0.8082\n",
      "Learning rate:  0.001\n",
      "Epoch 25/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.1379 - acc: 0.9540 - val_loss: 0.8737 - val_acc: 0.8044\n",
      "Learning rate:  0.001\n",
      "Epoch 26/200\n",
      "50000/50000 [==============================] - 11s - loss: 0.1295 - acc: 0.9570 - val_loss: 0.9210 - val_acc: 0.8096\n",
      "Learning rate:  0.001\n",
      "Epoch 27/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.1295 - acc: 0.9580 - val_loss: 0.9492 - val_acc: 0.8020\n",
      "Learning rate:  0.001\n",
      "Epoch 28/200\n",
      "50000/50000 [==============================] - 11s - loss: 0.1301 - acc: 0.9571 - val_loss: 0.9633 - val_acc: 0.8135\n",
      "Learning rate:  0.001\n",
      "Epoch 29/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.1158 - acc: 0.9620 - val_loss: 1.0485 - val_acc: 0.7976\n",
      "Learning rate:  0.001\n",
      "Epoch 30/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.1130 - acc: 0.9635 - val_loss: 0.9919 - val_acc: 0.8089\n",
      "Learning rate:  0.001\n",
      "Epoch 31/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.1134 - acc: 0.9630 - val_loss: 1.0349 - val_acc: 0.8000\n",
      "Learning rate:  0.001\n",
      "Epoch 32/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.1129 - acc: 0.9640 - val_loss: 0.9714 - val_acc: 0.8029\n",
      "Learning rate:  0.001\n",
      "Epoch 33/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.1098 - acc: 0.9643 - val_loss: 1.0304 - val_acc: 0.8035\n",
      "Learning rate:  0.001\n",
      "Epoch 34/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.1037 - acc: 0.9655 - val_loss: 1.0010 - val_acc: 0.8100\n",
      "Learning rate:  0.001\n",
      "Epoch 35/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.1042 - acc: 0.9668 - val_loss: 1.1083 - val_acc: 0.8070\n",
      "Learning rate:  0.001\n",
      "Epoch 36/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0976 - acc: 0.9678 - val_loss: 1.0453 - val_acc: 0.8048\n",
      "Learning rate:  0.001\n",
      "Epoch 37/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0976 - acc: 0.9699 - val_loss: 1.0555 - val_acc: 0.8094\n",
      "Learning rate:  0.001\n",
      "Epoch 38/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0955 - acc: 0.9694 - val_loss: 1.1152 - val_acc: 0.8085\n",
      "Learning rate:  0.001\n",
      "Epoch 39/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0926 - acc: 0.9711 - val_loss: 1.1094 - val_acc: 0.8043\n",
      "Learning rate:  0.001\n",
      "Epoch 40/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0954 - acc: 0.9707 - val_loss: 1.0813 - val_acc: 0.8100\n",
      "Learning rate:  0.001\n",
      "Epoch 41/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0901 - acc: 0.9720 - val_loss: 1.1252 - val_acc: 0.8081\n",
      "Learning rate:  0.001\n",
      "Epoch 42/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0880 - acc: 0.9718 - val_loss: 1.0617 - val_acc: 0.8072\n",
      "Learning rate:  0.001\n",
      "Epoch 43/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0918 - acc: 0.9714 - val_loss: 1.1196 - val_acc: 0.8102\n",
      "Learning rate:  0.001\n",
      "Epoch 44/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0891 - acc: 0.9739 - val_loss: 1.1160 - val_acc: 0.8095\n",
      "Learning rate:  0.001\n",
      "Epoch 45/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0860 - acc: 0.9726 - val_loss: 1.0965 - val_acc: 0.8007\n",
      "Learning rate:  0.001\n",
      "Epoch 46/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0855 - acc: 0.9745 - val_loss: 1.1598 - val_acc: 0.8119\n",
      "Learning rate:  0.001\n",
      "Epoch 47/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0810 - acc: 0.9751 - val_loss: 1.1348 - val_acc: 0.8166\n",
      "Learning rate:  0.001\n",
      "Epoch 48/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0806 - acc: 0.9756 - val_loss: 1.1014 - val_acc: 0.8088\n",
      "Learning rate:  0.001\n",
      "Epoch 49/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0858 - acc: 0.9744 - val_loss: 1.1232 - val_acc: 0.8049\n",
      "Learning rate:  0.001\n",
      "Epoch 50/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0843 - acc: 0.9743 - val_loss: 1.1765 - val_acc: 0.7963\n",
      "Learning rate:  0.001\n",
      "Epoch 51/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0794 - acc: 0.9764 - val_loss: 1.1986 - val_acc: 0.8083\n",
      "Learning rate:  0.001\n",
      "Epoch 52/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0799 - acc: 0.9755 - val_loss: 1.1724 - val_acc: 0.8063\n",
      "Learning rate:  0.001\n",
      "Epoch 53/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0786 - acc: 0.9765 - val_loss: 1.2457 - val_acc: 0.8141\n",
      "Learning rate:  0.001\n",
      "Epoch 54/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0750 - acc: 0.9767 - val_loss: 1.2844 - val_acc: 0.8092\n",
      "Learning rate:  0.001\n",
      "Epoch 55/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0733 - acc: 0.9780 - val_loss: 1.2970 - val_acc: 0.8123\n",
      "Learning rate:  0.001\n",
      "Epoch 56/200\n",
      "50000/50000 [==============================] - 11s - loss: 0.0778 - acc: 0.9777 - val_loss: 1.2123 - val_acc: 0.8084\n",
      "Learning rate:  0.001\n",
      "Epoch 57/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0690 - acc: 0.9789 - val_loss: 1.2837 - val_acc: 0.8113\n",
      "Learning rate:  0.001\n",
      "Epoch 58/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0730 - acc: 0.9788 - val_loss: 1.2409 - val_acc: 0.8049\n",
      "Learning rate:  0.001\n",
      "Epoch 59/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0716 - acc: 0.9787 - val_loss: 1.2252 - val_acc: 0.8135\n",
      "Learning rate:  0.001\n",
      "Epoch 60/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0741 - acc: 0.9786 - val_loss: 1.2731 - val_acc: 0.8052\n",
      "Learning rate:  0.001\n",
      "Epoch 61/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0721 - acc: 0.9793 - val_loss: 1.3102 - val_acc: 0.8155\n",
      "Learning rate:  0.001\n",
      "Epoch 62/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0692 - acc: 0.9798 - val_loss: 1.2973 - val_acc: 0.8061\n",
      "Learning rate:  0.001\n",
      "Epoch 63/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0699 - acc: 0.9795 - val_loss: 1.2953 - val_acc: 0.8106\n",
      "Learning rate:  0.001\n",
      "Epoch 64/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0722 - acc: 0.9797 - val_loss: 1.2997 - val_acc: 0.8109\n",
      "Learning rate:  0.001\n",
      "Epoch 65/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0703 - acc: 0.9795 - val_loss: 1.3090 - val_acc: 0.8122\n",
      "Learning rate:  0.001\n",
      "Epoch 66/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0704 - acc: 0.9799 - val_loss: 1.2830 - val_acc: 0.8071\n",
      "Learning rate:  0.001\n",
      "Epoch 67/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0651 - acc: 0.9813 - val_loss: 1.3390 - val_acc: 0.8029\n",
      "Learning rate:  0.001\n",
      "Epoch 68/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0682 - acc: 0.9798 - val_loss: 1.3438 - val_acc: 0.8068\n",
      "Learning rate:  0.001\n",
      "Epoch 69/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0709 - acc: 0.9804 - val_loss: 1.3667 - val_acc: 0.8096\n",
      "Learning rate:  0.001\n",
      "Epoch 70/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0656 - acc: 0.9819 - val_loss: 1.5030 - val_acc: 0.8123\n",
      "Learning rate:  0.001\n",
      "Epoch 71/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0652 - acc: 0.9817 - val_loss: 1.2606 - val_acc: 0.8072\n",
      "Learning rate:  0.001\n",
      "Epoch 72/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0679 - acc: 0.9810 - val_loss: 1.5582 - val_acc: 0.8033\n",
      "Learning rate:  0.001\n",
      "Epoch 73/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0685 - acc: 0.9809 - val_loss: 1.3878 - val_acc: 0.8096\n",
      "Learning rate:  0.001\n",
      "Epoch 74/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0662 - acc: 0.9818 - val_loss: 1.4361 - val_acc: 0.8131\n",
      "Learning rate:  0.001\n",
      "Epoch 75/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0653 - acc: 0.9826 - val_loss: 1.3837 - val_acc: 0.8048\n",
      "Learning rate:  0.001\n",
      "Epoch 76/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0632 - acc: 0.9821 - val_loss: 1.3927 - val_acc: 0.8104\n",
      "Learning rate:  0.001\n",
      "Epoch 77/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0596 - acc: 0.9837 - val_loss: 1.5205 - val_acc: 0.8084\n",
      "Learning rate:  0.001\n",
      "Epoch 78/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0654 - acc: 0.9822 - val_loss: 1.4264 - val_acc: 0.8107\n",
      "Learning rate:  0.001\n",
      "Epoch 79/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0641 - acc: 0.9831 - val_loss: 1.4071 - val_acc: 0.8066\n",
      "Learning rate:  0.001\n",
      "Epoch 80/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0635 - acc: 0.9836 - val_loss: 1.4758 - val_acc: 0.8062\n",
      "Learning rate:  0.001\n",
      "Epoch 81/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0618 - acc: 0.9839 - val_loss: 1.5661 - val_acc: 0.7998\n",
      "Learning rate:  0.0001\n",
      "Epoch 82/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0366 - acc: 0.9898 - val_loss: 1.4395 - val_acc: 0.8170\n",
      "Learning rate:  0.0001\n",
      "Epoch 83/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0255 - acc: 0.9925 - val_loss: 1.3942 - val_acc: 0.8162\n",
      "Learning rate:  0.0001\n",
      "Epoch 84/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0198 - acc: 0.9940 - val_loss: 1.4311 - val_acc: 0.8198\n",
      "Learning rate:  0.0001\n",
      "Epoch 85/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0209 - acc: 0.9937 - val_loss: 1.4520 - val_acc: 0.8192\n",
      "Learning rate:  0.0001\n",
      "Epoch 86/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0187 - acc: 0.9941 - val_loss: 1.3933 - val_acc: 0.8208\n",
      "Learning rate:  0.0001\n",
      "Epoch 87/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0170 - acc: 0.9951 - val_loss: 1.4111 - val_acc: 0.8217\n",
      "Learning rate:  0.0001\n",
      "Epoch 88/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0174 - acc: 0.9947 - val_loss: 1.4141 - val_acc: 0.8221\n",
      "Learning rate:  0.0001\n",
      "Epoch 89/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0163 - acc: 0.9951 - val_loss: 1.4071 - val_acc: 0.8211\n",
      "Learning rate:  0.0001\n",
      "Epoch 90/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0160 - acc: 0.9957 - val_loss: 1.3911 - val_acc: 0.8210\n",
      "Learning rate:  0.0001\n",
      "Epoch 91/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0158 - acc: 0.9953 - val_loss: 1.3977 - val_acc: 0.8200\n",
      "Learning rate:  0.0001\n",
      "Epoch 92/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0162 - acc: 0.9952 - val_loss: 1.3912 - val_acc: 0.8197\n",
      "Learning rate:  0.0001\n",
      "Epoch 93/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0148 - acc: 0.9954 - val_loss: 1.3752 - val_acc: 0.8195\n",
      "Learning rate:  0.0001\n",
      "Epoch 94/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0143 - acc: 0.9955 - val_loss: 1.3986 - val_acc: 0.8210\n",
      "Learning rate:  0.0001\n",
      "Epoch 95/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0147 - acc: 0.9956 - val_loss: 1.4042 - val_acc: 0.8222\n",
      "Learning rate:  0.0001\n",
      "Epoch 96/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0131 - acc: 0.9961 - val_loss: 1.3812 - val_acc: 0.8234\n",
      "Learning rate:  0.0001\n",
      "Epoch 97/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0148 - acc: 0.9957 - val_loss: 1.3642 - val_acc: 0.8232\n",
      "Learning rate:  0.0001\n",
      "Epoch 98/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0142 - acc: 0.9956 - val_loss: 1.3904 - val_acc: 0.8212\n",
      "Learning rate:  0.0001\n",
      "Epoch 99/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0129 - acc: 0.9963 - val_loss: 1.3868 - val_acc: 0.8229\n",
      "Learning rate:  0.0001\n",
      "Epoch 100/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0150 - acc: 0.9952 - val_loss: 1.3562 - val_acc: 0.8237\n",
      "Learning rate:  0.0001\n",
      "Epoch 101/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0145 - acc: 0.9959 - val_loss: 1.3880 - val_acc: 0.8236\n",
      "Learning rate:  0.0001\n",
      "Epoch 102/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0136 - acc: 0.9959 - val_loss: 1.3956 - val_acc: 0.8230\n",
      "Learning rate:  0.0001\n",
      "Epoch 103/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0133 - acc: 0.9962 - val_loss: 1.3783 - val_acc: 0.8245\n",
      "Learning rate:  0.0001\n",
      "Epoch 104/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0122 - acc: 0.9960 - val_loss: 1.3712 - val_acc: 0.8240\n",
      "Learning rate:  0.0001\n",
      "Epoch 105/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0126 - acc: 0.9961 - val_loss: 1.3683 - val_acc: 0.8233\n",
      "Learning rate:  0.0001\n",
      "Epoch 106/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0124 - acc: 0.9963 - val_loss: 1.3821 - val_acc: 0.8238\n",
      "Learning rate:  0.0001\n",
      "Epoch 107/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 12s - loss: 0.0123 - acc: 0.9963 - val_loss: 1.3901 - val_acc: 0.8238\n",
      "Learning rate:  0.0001\n",
      "Epoch 108/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0121 - acc: 0.9962 - val_loss: 1.3975 - val_acc: 0.8240\n",
      "Learning rate:  0.0001\n",
      "Epoch 109/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0120 - acc: 0.9963 - val_loss: 1.3933 - val_acc: 0.8230\n",
      "Learning rate:  0.0001\n",
      "Epoch 110/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0129 - acc: 0.9960 - val_loss: 1.3890 - val_acc: 0.8223\n",
      "Learning rate:  0.0001\n",
      "Epoch 111/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0108 - acc: 0.9964 - val_loss: 1.3733 - val_acc: 0.8231\n",
      "Learning rate:  0.0001\n",
      "Epoch 112/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0101 - acc: 0.9970 - val_loss: 1.3787 - val_acc: 0.8243\n",
      "Learning rate:  0.0001\n",
      "Epoch 113/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0121 - acc: 0.9963 - val_loss: 1.3771 - val_acc: 0.8237\n",
      "Learning rate:  0.0001\n",
      "Epoch 114/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0124 - acc: 0.9963 - val_loss: 1.3983 - val_acc: 0.8237\n",
      "Learning rate:  0.0001\n",
      "Epoch 115/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0119 - acc: 0.9963 - val_loss: 1.3765 - val_acc: 0.8247\n",
      "Learning rate:  0.0001\n",
      "Epoch 116/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0128 - acc: 0.9963 - val_loss: 1.4065 - val_acc: 0.8244\n",
      "Learning rate:  0.0001\n",
      "Epoch 117/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0120 - acc: 0.9965 - val_loss: 1.3933 - val_acc: 0.8232\n",
      "Learning rate:  0.0001\n",
      "Epoch 118/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0124 - acc: 0.9959 - val_loss: 1.3886 - val_acc: 0.8243\n",
      "Learning rate:  0.0001\n",
      "Epoch 119/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0126 - acc: 0.9964 - val_loss: 1.3706 - val_acc: 0.8228\n",
      "Learning rate:  0.0001\n",
      "Epoch 120/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0122 - acc: 0.9965 - val_loss: 1.3455 - val_acc: 0.8244\n",
      "Learning rate:  0.0001\n",
      "Epoch 121/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0107 - acc: 0.9967 - val_loss: 1.3739 - val_acc: 0.8236\n",
      "Learning rate:  1e-05\n",
      "Epoch 122/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0132 - acc: 0.9962 - val_loss: 1.3693 - val_acc: 0.8244\n",
      "Learning rate:  1e-05\n",
      "Epoch 123/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0109 - acc: 0.9964 - val_loss: 1.3724 - val_acc: 0.8249\n",
      "Learning rate:  1e-05\n",
      "Epoch 124/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0108 - acc: 0.9966 - val_loss: 1.3760 - val_acc: 0.8247\n",
      "Learning rate:  1e-05\n",
      "Epoch 125/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0104 - acc: 0.9967 - val_loss: 1.3818 - val_acc: 0.8248\n",
      "Learning rate:  1e-05\n",
      "Epoch 126/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0090 - acc: 0.9969 - val_loss: 1.3801 - val_acc: 0.8251\n",
      "Learning rate:  1e-05\n",
      "Epoch 127/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0102 - acc: 0.9968 - val_loss: 1.3758 - val_acc: 0.8252\n",
      "Learning rate:  1e-05\n",
      "Epoch 128/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0107 - acc: 0.9969 - val_loss: 1.3819 - val_acc: 0.8250\n",
      "Learning rate:  1e-05\n",
      "Epoch 129/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0119 - acc: 0.9968 - val_loss: 1.3771 - val_acc: 0.8255\n",
      "Learning rate:  1e-05\n",
      "Epoch 130/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0105 - acc: 0.9966 - val_loss: 1.3781 - val_acc: 0.8252\n",
      "Learning rate:  1e-05\n",
      "Epoch 131/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0111 - acc: 0.9967 - val_loss: 1.3736 - val_acc: 0.8258\n",
      "Learning rate:  1e-05\n",
      "Epoch 132/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0090 - acc: 0.9970 - val_loss: 1.3749 - val_acc: 0.8259\n",
      "Learning rate:  1e-05\n",
      "Epoch 133/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0111 - acc: 0.9966 - val_loss: 1.3668 - val_acc: 0.8255\n",
      "Learning rate:  1e-05\n",
      "Epoch 134/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0093 - acc: 0.9973 - val_loss: 1.3784 - val_acc: 0.8259\n",
      "Learning rate:  1e-05\n",
      "Epoch 135/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0094 - acc: 0.9972 - val_loss: 1.3770 - val_acc: 0.8259\n",
      "Learning rate:  1e-05\n",
      "Epoch 136/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0101 - acc: 0.9973 - val_loss: 1.3734 - val_acc: 0.8264\n",
      "Learning rate:  1e-05\n",
      "Epoch 137/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0089 - acc: 0.9972 - val_loss: 1.3790 - val_acc: 0.8251\n",
      "Learning rate:  1e-05\n",
      "Epoch 138/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0101 - acc: 0.9971 - val_loss: 1.3796 - val_acc: 0.8254\n",
      "Learning rate:  1e-05\n",
      "Epoch 139/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0108 - acc: 0.9970 - val_loss: 1.3797 - val_acc: 0.8255\n",
      "Learning rate:  1e-05\n",
      "Epoch 140/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0098 - acc: 0.9971 - val_loss: 1.3705 - val_acc: 0.8262\n",
      "Learning rate:  1e-05\n",
      "Epoch 141/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0101 - acc: 0.9967 - val_loss: 1.3751 - val_acc: 0.8256\n",
      "Learning rate:  1e-05\n",
      "Epoch 142/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0119 - acc: 0.9967 - val_loss: 1.3751 - val_acc: 0.8259\n",
      "Learning rate:  1e-05\n",
      "Epoch 143/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0122 - acc: 0.9967 - val_loss: 1.3711 - val_acc: 0.8248\n",
      "Learning rate:  1e-05\n",
      "Epoch 144/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0102 - acc: 0.9969 - val_loss: 1.3676 - val_acc: 0.8254\n",
      "Learning rate:  1e-05\n",
      "Epoch 145/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0103 - acc: 0.9971 - val_loss: 1.3684 - val_acc: 0.8263\n",
      "Learning rate:  1e-05\n",
      "Epoch 146/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0102 - acc: 0.9967 - val_loss: 1.3686 - val_acc: 0.8260\n",
      "Learning rate:  1e-05\n",
      "Epoch 147/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0103 - acc: 0.9970 - val_loss: 1.3692 - val_acc: 0.8252\n",
      "Learning rate:  1e-05\n",
      "Epoch 148/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0090 - acc: 0.9973 - val_loss: 1.3775 - val_acc: 0.8261\n",
      "Learning rate:  1e-05\n",
      "Epoch 149/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0092 - acc: 0.9972 - val_loss: 1.3725 - val_acc: 0.8261\n",
      "Learning rate:  1e-05\n",
      "Epoch 150/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0098 - acc: 0.9968 - val_loss: 1.3715 - val_acc: 0.8253\n",
      "Learning rate:  1e-05\n",
      "Epoch 151/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0099 - acc: 0.9969 - val_loss: 1.3717 - val_acc: 0.8258\n",
      "Learning rate:  1e-06\n",
      "Epoch 152/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0102 - acc: 0.9966 - val_loss: 1.3715 - val_acc: 0.8258\n",
      "Learning rate:  1e-06\n",
      "Epoch 153/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0094 - acc: 0.9971 - val_loss: 1.3697 - val_acc: 0.8258\n",
      "Learning rate:  1e-06\n",
      "Epoch 154/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0088 - acc: 0.9972 - val_loss: 1.3703 - val_acc: 0.8256\n",
      "Learning rate:  1e-06\n",
      "Epoch 155/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0113 - acc: 0.9966 - val_loss: 1.3709 - val_acc: 0.8256\n",
      "Learning rate:  1e-06\n",
      "Epoch 156/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0099 - acc: 0.9969 - val_loss: 1.3704 - val_acc: 0.8258\n",
      "Learning rate:  1e-06\n",
      "Epoch 157/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0091 - acc: 0.9971 - val_loss: 1.3705 - val_acc: 0.8252\n",
      "Learning rate:  1e-06\n",
      "Epoch 158/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0086 - acc: 0.9975 - val_loss: 1.3755 - val_acc: 0.8253\n",
      "Learning rate:  1e-06\n",
      "Epoch 159/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0097 - acc: 0.9972 - val_loss: 1.3714 - val_acc: 0.8259\n",
      "Learning rate:  1e-06\n",
      "Epoch 160/200\n",
      "50000/50000 [==============================] - 11s - loss: 0.0106 - acc: 0.9969 - val_loss: 1.3714 - val_acc: 0.8255\n",
      "Learning rate:  1e-06\n",
      "Epoch 161/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0101 - acc: 0.9966 - val_loss: 1.3701 - val_acc: 0.8258\n",
      "Learning rate:  1e-06\n",
      "Epoch 162/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0094 - acc: 0.9967 - val_loss: 1.3729 - val_acc: 0.8260\n",
      "Learning rate:  1e-06\n",
      "Epoch 163/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0096 - acc: 0.9969 - val_loss: 1.3724 - val_acc: 0.8257\n",
      "Learning rate:  1e-06\n",
      "Epoch 164/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0089 - acc: 0.9970 - val_loss: 1.3695 - val_acc: 0.8255\n",
      "Learning rate:  1e-06\n",
      "Epoch 165/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0107 - acc: 0.9971 - val_loss: 1.3726 - val_acc: 0.8263\n",
      "Learning rate:  1e-06\n",
      "Epoch 166/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0103 - acc: 0.9966 - val_loss: 1.3714 - val_acc: 0.8255\n",
      "Learning rate:  1e-06\n",
      "Epoch 167/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0107 - acc: 0.9970 - val_loss: 1.3675 - val_acc: 0.8258\n",
      "Learning rate:  1e-06\n",
      "Epoch 168/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0084 - acc: 0.9974 - val_loss: 1.3712 - val_acc: 0.8260\n",
      "Learning rate:  1e-06\n",
      "Epoch 169/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0114 - acc: 0.9967 - val_loss: 1.3714 - val_acc: 0.8256\n",
      "Learning rate:  1e-06\n",
      "Epoch 170/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0094 - acc: 0.9969 - val_loss: 1.3706 - val_acc: 0.8264\n",
      "Learning rate:  1e-06\n",
      "Epoch 171/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0100 - acc: 0.9969 - val_loss: 1.3732 - val_acc: 0.8260\n",
      "Learning rate:  1e-06\n",
      "Epoch 172/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0109 - acc: 0.9967 - val_loss: 1.3712 - val_acc: 0.8257\n",
      "Learning rate:  1e-06\n",
      "Epoch 173/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0092 - acc: 0.9971 - val_loss: 1.3683 - val_acc: 0.8255\n",
      "Learning rate:  1e-06\n",
      "Epoch 174/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0104 - acc: 0.9969 - val_loss: 1.3738 - val_acc: 0.8253\n",
      "Learning rate:  1e-06\n",
      "Epoch 175/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0109 - acc: 0.9967 - val_loss: 1.3722 - val_acc: 0.8255\n",
      "Learning rate:  1e-06\n",
      "Epoch 176/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0088 - acc: 0.9973 - val_loss: 1.3749 - val_acc: 0.8264\n",
      "Learning rate:  1e-06\n",
      "Epoch 177/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0094 - acc: 0.9970 - val_loss: 1.3724 - val_acc: 0.8258\n",
      "Learning rate:  1e-06\n",
      "Epoch 178/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0082 - acc: 0.9975 - val_loss: 1.3716 - val_acc: 0.8254\n",
      "Learning rate:  1e-06\n",
      "Epoch 179/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0105 - acc: 0.9968 - val_loss: 1.3730 - val_acc: 0.8258\n",
      "Learning rate:  1e-06\n",
      "Epoch 180/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0099 - acc: 0.9969 - val_loss: 1.3736 - val_acc: 0.8257\n",
      "Learning rate:  1e-06\n",
      "Epoch 181/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0091 - acc: 0.9971 - val_loss: 1.3730 - val_acc: 0.8265\n",
      "Learning rate:  5e-07\n",
      "Epoch 182/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0095 - acc: 0.9972 - val_loss: 1.3710 - val_acc: 0.8259\n",
      "Learning rate:  5e-07\n",
      "Epoch 183/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0092 - acc: 0.9970 - val_loss: 1.3722 - val_acc: 0.8262\n",
      "Learning rate:  5e-07\n",
      "Epoch 184/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0111 - acc: 0.9968 - val_loss: 1.3740 - val_acc: 0.8264\n",
      "Learning rate:  5e-07\n",
      "Epoch 185/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0109 - acc: 0.9969 - val_loss: 1.3728 - val_acc: 0.8257\n",
      "Learning rate:  5e-07\n",
      "Epoch 186/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0102 - acc: 0.9970 - val_loss: 1.3727 - val_acc: 0.8260\n",
      "Learning rate:  5e-07\n",
      "Epoch 187/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0113 - acc: 0.9966 - val_loss: 1.3713 - val_acc: 0.8258\n",
      "Learning rate:  5e-07\n",
      "Epoch 188/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0098 - acc: 0.9966 - val_loss: 1.3726 - val_acc: 0.8267\n",
      "Learning rate:  5e-07\n",
      "Epoch 189/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0076 - acc: 0.9974 - val_loss: 1.3714 - val_acc: 0.8264\n",
      "Learning rate:  5e-07\n",
      "Epoch 190/200\n",
      "50000/50000 [==============================] - 11s - loss: 0.0099 - acc: 0.9969 - val_loss: 1.3734 - val_acc: 0.8260\n",
      "Learning rate:  5e-07\n",
      "Epoch 191/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0116 - acc: 0.9966 - val_loss: 1.3719 - val_acc: 0.8253\n",
      "Learning rate:  5e-07\n",
      "Epoch 192/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0108 - acc: 0.9970 - val_loss: 1.3723 - val_acc: 0.8258\n",
      "Learning rate:  5e-07\n",
      "Epoch 193/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0099 - acc: 0.9973 - val_loss: 1.3731 - val_acc: 0.8255\n",
      "Learning rate:  5e-07\n",
      "Epoch 194/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0097 - acc: 0.9969 - val_loss: 1.3748 - val_acc: 0.8257\n",
      "Learning rate:  5e-07\n",
      "Epoch 195/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0093 - acc: 0.9972 - val_loss: 1.3730 - val_acc: 0.8258\n",
      "Learning rate:  5e-07\n",
      "Epoch 196/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0094 - acc: 0.9970 - val_loss: 1.3736 - val_acc: 0.8256\n",
      "Learning rate:  5e-07\n",
      "Epoch 197/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0087 - acc: 0.9971 - val_loss: 1.3731 - val_acc: 0.8260\n",
      "Learning rate:  5e-07\n",
      "Epoch 198/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0096 - acc: 0.9970 - val_loss: 1.3723 - val_acc: 0.8259\n",
      "Learning rate:  5e-07\n",
      "Epoch 199/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0089 - acc: 0.9974 - val_loss: 1.3736 - val_acc: 0.8262\n",
      "Learning rate:  5e-07\n",
      "Epoch 200/200\n",
      "50000/50000 [==============================] - 12s - loss: 0.0097 - acc: 0.9970 - val_loss: 1.3722 - val_acc: 0.8264\n",
      "Saved trained model at /home/thanawit/saved_models/keras_cifar10_trained_model.h5 \n"
     ]
    }
   ],
   "source": [
    "#Decaying LR\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-6)\n",
    "\n",
    "callbacks = [ lr_reducer, lr_scheduler]\n",
    "\n",
    "\n",
    "#train model \n",
    "model.fit(x_train , y_train, batch_size=batch_size , epochs= epochs , validation_data=(x_test, y_test), shuffle=True ,callbacks=callbacks)\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9952/10000 [============================>.] - ETA: 0sTest loss: 1.3721587099976837\n",
      "Test accuracy: 0.8264\n"
     ]
    }
   ],
   "source": [
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
